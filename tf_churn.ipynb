{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "\n",
       "   Tenure  Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "0       2      0.0              1          1               1        101348.88   \n",
       "\n",
       "   Exited  \n",
       "0       1  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Binary Prediction\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Import sklearn\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Import tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "# Load dataframe from dataset \n",
    "df = pd.read_csv('Input/Churn.csv')\n",
    "df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping some unnecessary dtypes that doesn't affect the dataframe (Or does not have any pattern)\n",
    "df.drop(columns=['RowNumber', 'CustomerId', 'Surname'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           10000 non-null  int64  \n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(2), int64(7), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check to see the what the datatypes are numerical or not\n",
    "df.info(verbose=True) # Geography and Gender are non num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42       2       0.00              1          1   \n",
       "1          608   41       1   83807.86              1          0   \n",
       "2          502   42       8  159660.80              3          1   \n",
       "3          699   39       1       0.00              2          0   \n",
       "4          850   43       2  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1        101348.88       1              False   \n",
       "1               1        112542.58       0              False   \n",
       "2               0        113931.57       1              False   \n",
       "3               0         93826.63       0              False   \n",
       "4               1         79084.10       0              False   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0            False        False  \n",
       "1             True        False  \n",
       "2            False        False  \n",
       "3            False        False  \n",
       "4             True        False  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 2 columns Geography and Gender into True and False\n",
    "df = pd.get_dummies(df,columns=['Geography','Gender'],drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Exited since it is label (output)\n",
    "X = df.drop(columns=['Exited'])\n",
    "y = df['Exited'].values # Return the value from y\n",
    "\n",
    "# Splitting the data into Train set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and then transform X_train, X_test\n",
    "X_train_trf = scaler.fit_transform(X_train)\n",
    "X_test_trf = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid Activation Function\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Dense(units= 11, activation='sigmoid', input_dim=11),\n",
    "    tf.keras.layers.Dense(units= 11, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(units= 1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 11)                132       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 11)                132       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 276 (1.08 KB)\n",
      "Trainable params: 276 (1.08 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign optimizer, loss function and metrics\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "128/128 [==============================] - 1s 2ms/step - loss: 0.6329 - accuracy: 0.6503 - val_loss: 0.5399 - val_accuracy: 0.7900\n",
      "Epoch 2/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7961 - val_loss: 0.5039 - val_accuracy: 0.7900\n",
      "Epoch 3/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.7961 - val_loss: 0.4945 - val_accuracy: 0.7900\n",
      "Epoch 4/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4806 - accuracy: 0.7961 - val_loss: 0.4870 - val_accuracy: 0.7900\n",
      "Epoch 5/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7961 - val_loss: 0.4798 - val_accuracy: 0.7900\n",
      "Epoch 6/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7961 - val_loss: 0.4729 - val_accuracy: 0.7900\n",
      "Epoch 7/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7961 - val_loss: 0.4659 - val_accuracy: 0.7900\n",
      "Epoch 8/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4526 - accuracy: 0.7961 - val_loss: 0.4597 - val_accuracy: 0.7900\n",
      "Epoch 9/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.7961 - val_loss: 0.4536 - val_accuracy: 0.7900\n",
      "Epoch 10/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.7961 - val_loss: 0.4489 - val_accuracy: 0.7912\n",
      "Epoch 11/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.8014 - val_loss: 0.4449 - val_accuracy: 0.8012\n",
      "Epoch 12/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4327 - accuracy: 0.8097 - val_loss: 0.4417 - val_accuracy: 0.8050\n",
      "Epoch 13/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.8123 - val_loss: 0.4390 - val_accuracy: 0.8100\n",
      "Epoch 14/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.8147 - val_loss: 0.4373 - val_accuracy: 0.8125\n",
      "Epoch 15/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4246 - accuracy: 0.8159 - val_loss: 0.4355 - val_accuracy: 0.8144\n",
      "Epoch 16/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4227 - accuracy: 0.8184 - val_loss: 0.4342 - val_accuracy: 0.8156\n",
      "Epoch 17/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4208 - accuracy: 0.8209 - val_loss: 0.4330 - val_accuracy: 0.8175\n",
      "Epoch 18/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4191 - accuracy: 0.8220 - val_loss: 0.4320 - val_accuracy: 0.8200\n",
      "Epoch 19/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4174 - accuracy: 0.8214 - val_loss: 0.4308 - val_accuracy: 0.8194\n",
      "Epoch 20/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4157 - accuracy: 0.8231 - val_loss: 0.4295 - val_accuracy: 0.8194\n",
      "Epoch 21/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4141 - accuracy: 0.8241 - val_loss: 0.4284 - val_accuracy: 0.8225\n",
      "Epoch 22/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4128 - accuracy: 0.8264 - val_loss: 0.4274 - val_accuracy: 0.8238\n",
      "Epoch 23/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4113 - accuracy: 0.8280 - val_loss: 0.4267 - val_accuracy: 0.8225\n",
      "Epoch 24/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4098 - accuracy: 0.8288 - val_loss: 0.4254 - val_accuracy: 0.8225\n",
      "Epoch 25/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4085 - accuracy: 0.8313 - val_loss: 0.4245 - val_accuracy: 0.8213\n",
      "Epoch 26/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4071 - accuracy: 0.8309 - val_loss: 0.4234 - val_accuracy: 0.8238\n",
      "Epoch 27/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4057 - accuracy: 0.8320 - val_loss: 0.4224 - val_accuracy: 0.8231\n",
      "Epoch 28/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4045 - accuracy: 0.8323 - val_loss: 0.4214 - val_accuracy: 0.8225\n",
      "Epoch 29/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4029 - accuracy: 0.8344 - val_loss: 0.4198 - val_accuracy: 0.8250\n",
      "Epoch 30/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.4013 - accuracy: 0.8350 - val_loss: 0.4185 - val_accuracy: 0.8288\n",
      "Epoch 31/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3995 - accuracy: 0.8364 - val_loss: 0.4179 - val_accuracy: 0.8256\n",
      "Epoch 32/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3983 - accuracy: 0.8370 - val_loss: 0.4159 - val_accuracy: 0.8269\n",
      "Epoch 33/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3966 - accuracy: 0.8372 - val_loss: 0.4152 - val_accuracy: 0.8263\n",
      "Epoch 34/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3954 - accuracy: 0.8383 - val_loss: 0.4133 - val_accuracy: 0.8294\n",
      "Epoch 35/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3938 - accuracy: 0.8384 - val_loss: 0.4121 - val_accuracy: 0.8300\n",
      "Epoch 36/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3924 - accuracy: 0.8384 - val_loss: 0.4105 - val_accuracy: 0.8294\n",
      "Epoch 37/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3911 - accuracy: 0.8381 - val_loss: 0.4091 - val_accuracy: 0.8281\n",
      "Epoch 38/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3898 - accuracy: 0.8389 - val_loss: 0.4078 - val_accuracy: 0.8294\n",
      "Epoch 39/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3885 - accuracy: 0.8386 - val_loss: 0.4072 - val_accuracy: 0.8338\n",
      "Epoch 40/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8405 - val_loss: 0.4054 - val_accuracy: 0.8313\n",
      "Epoch 41/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3858 - accuracy: 0.8402 - val_loss: 0.4039 - val_accuracy: 0.8313\n",
      "Epoch 42/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3847 - accuracy: 0.8414 - val_loss: 0.4026 - val_accuracy: 0.8313\n",
      "Epoch 43/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3833 - accuracy: 0.8411 - val_loss: 0.4010 - val_accuracy: 0.8338\n",
      "Epoch 44/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3820 - accuracy: 0.8423 - val_loss: 0.3997 - val_accuracy: 0.8331\n",
      "Epoch 45/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3805 - accuracy: 0.8428 - val_loss: 0.3984 - val_accuracy: 0.8344\n",
      "Epoch 46/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3792 - accuracy: 0.8425 - val_loss: 0.3968 - val_accuracy: 0.8369\n",
      "Epoch 47/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3781 - accuracy: 0.8453 - val_loss: 0.3959 - val_accuracy: 0.8369\n",
      "Epoch 48/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3765 - accuracy: 0.8442 - val_loss: 0.3950 - val_accuracy: 0.8350\n",
      "Epoch 49/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3755 - accuracy: 0.8475 - val_loss: 0.3930 - val_accuracy: 0.8388\n",
      "Epoch 50/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8478 - val_loss: 0.3914 - val_accuracy: 0.8381\n",
      "Epoch 51/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3725 - accuracy: 0.8480 - val_loss: 0.3899 - val_accuracy: 0.8406\n",
      "Epoch 52/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8489 - val_loss: 0.3885 - val_accuracy: 0.8400\n",
      "Epoch 53/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3701 - accuracy: 0.8481 - val_loss: 0.3877 - val_accuracy: 0.8406\n",
      "Epoch 54/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3690 - accuracy: 0.8491 - val_loss: 0.3866 - val_accuracy: 0.8406\n",
      "Epoch 55/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.8498 - val_loss: 0.3849 - val_accuracy: 0.8419\n",
      "Epoch 56/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3666 - accuracy: 0.8506 - val_loss: 0.3836 - val_accuracy: 0.8419\n",
      "Epoch 57/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3655 - accuracy: 0.8506 - val_loss: 0.3825 - val_accuracy: 0.8425\n",
      "Epoch 58/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3644 - accuracy: 0.8498 - val_loss: 0.3814 - val_accuracy: 0.8425\n",
      "Epoch 59/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3629 - accuracy: 0.8522 - val_loss: 0.3829 - val_accuracy: 0.8450\n",
      "Epoch 60/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3622 - accuracy: 0.8525 - val_loss: 0.3795 - val_accuracy: 0.8431\n",
      "Epoch 61/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.8536 - val_loss: 0.3784 - val_accuracy: 0.8431\n",
      "Epoch 62/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8533 - val_loss: 0.3781 - val_accuracy: 0.8444\n",
      "Epoch 63/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8542 - val_loss: 0.3768 - val_accuracy: 0.8456\n",
      "Epoch 64/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3585 - accuracy: 0.8547 - val_loss: 0.3771 - val_accuracy: 0.8462\n",
      "Epoch 65/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.8577 - val_loss: 0.3750 - val_accuracy: 0.8456\n",
      "Epoch 66/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3570 - accuracy: 0.8570 - val_loss: 0.3741 - val_accuracy: 0.8462\n",
      "Epoch 67/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3558 - accuracy: 0.8559 - val_loss: 0.3734 - val_accuracy: 0.8450\n",
      "Epoch 68/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3550 - accuracy: 0.8566 - val_loss: 0.3742 - val_accuracy: 0.8487\n",
      "Epoch 69/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3543 - accuracy: 0.8567 - val_loss: 0.3720 - val_accuracy: 0.8475\n",
      "Epoch 70/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3533 - accuracy: 0.8564 - val_loss: 0.3716 - val_accuracy: 0.8444\n",
      "Epoch 71/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3527 - accuracy: 0.8581 - val_loss: 0.3707 - val_accuracy: 0.8462\n",
      "Epoch 72/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3518 - accuracy: 0.8573 - val_loss: 0.3701 - val_accuracy: 0.8481\n",
      "Epoch 73/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.8575 - val_loss: 0.3693 - val_accuracy: 0.8450\n",
      "Epoch 74/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3504 - accuracy: 0.8595 - val_loss: 0.3686 - val_accuracy: 0.8469\n",
      "Epoch 75/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3495 - accuracy: 0.8586 - val_loss: 0.3677 - val_accuracy: 0.8487\n",
      "Epoch 76/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3488 - accuracy: 0.8594 - val_loss: 0.3675 - val_accuracy: 0.8487\n",
      "Epoch 77/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3480 - accuracy: 0.8608 - val_loss: 0.3664 - val_accuracy: 0.8481\n",
      "Epoch 78/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.8606 - val_loss: 0.3657 - val_accuracy: 0.8487\n",
      "Epoch 79/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3468 - accuracy: 0.8602 - val_loss: 0.3652 - val_accuracy: 0.8481\n",
      "Epoch 80/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3459 - accuracy: 0.8609 - val_loss: 0.3647 - val_accuracy: 0.8487\n",
      "Epoch 81/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.8609 - val_loss: 0.3641 - val_accuracy: 0.8487\n",
      "Epoch 82/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.8617 - val_loss: 0.3633 - val_accuracy: 0.8487\n",
      "Epoch 83/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3442 - accuracy: 0.8617 - val_loss: 0.3627 - val_accuracy: 0.8481\n",
      "Epoch 84/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3435 - accuracy: 0.8609 - val_loss: 0.3624 - val_accuracy: 0.8481\n",
      "Epoch 85/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3427 - accuracy: 0.8627 - val_loss: 0.3615 - val_accuracy: 0.8506\n",
      "Epoch 86/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3423 - accuracy: 0.8611 - val_loss: 0.3611 - val_accuracy: 0.8506\n",
      "Epoch 87/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3414 - accuracy: 0.8625 - val_loss: 0.3609 - val_accuracy: 0.8494\n",
      "Epoch 88/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3413 - accuracy: 0.8609 - val_loss: 0.3604 - val_accuracy: 0.8494\n",
      "Epoch 89/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.8630 - val_loss: 0.3601 - val_accuracy: 0.8512\n",
      "Epoch 90/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3400 - accuracy: 0.8620 - val_loss: 0.3594 - val_accuracy: 0.8531\n",
      "Epoch 91/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.8627 - val_loss: 0.3591 - val_accuracy: 0.8494\n",
      "Epoch 92/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3390 - accuracy: 0.8614 - val_loss: 0.3583 - val_accuracy: 0.8506\n",
      "Epoch 93/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3383 - accuracy: 0.8602 - val_loss: 0.3577 - val_accuracy: 0.8519\n",
      "Epoch 94/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.8612 - val_loss: 0.3576 - val_accuracy: 0.8512\n",
      "Epoch 95/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8620 - val_loss: 0.3574 - val_accuracy: 0.8525\n",
      "Epoch 96/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8628 - val_loss: 0.3565 - val_accuracy: 0.8531\n",
      "Epoch 97/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8622 - val_loss: 0.3561 - val_accuracy: 0.8531\n",
      "Epoch 98/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8633 - val_loss: 0.3556 - val_accuracy: 0.8531\n",
      "Epoch 99/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8608 - val_loss: 0.3559 - val_accuracy: 0.8519\n",
      "Epoch 100/100\n",
      "128/128 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8620 - val_loss: 0.3551 - val_accuracy: 0.8544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x14b00a090>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting X_train and y_train to tensors\n",
    "X_train_tensor = tf.convert_to_tensor(X_train_trf)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train)\n",
    "\n",
    "X_test_tensor = tf.convert_to_tensor(X_test_trf)\n",
    "\n",
    "# Fitting the model to reduce losses\n",
    "model.fit(X_train_tensor, y_train_tensor, batch_size=50, epochs=100, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 771us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.05689274],\n",
       "       [0.00877046],\n",
       "       [0.1615263 ],\n",
       "       ...,\n",
       "       [0.2855632 ],\n",
       "       [0.17448764],\n",
       "       [0.16528569]], dtype=float32)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all y prediction based on test model tensors\n",
    "y_pred = model.predict(X_test_tensor)\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get maximum number with axis = -1 in all y prediction\n",
    "y_pred = y_pred.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.802"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking accuracy score\n",
    "sk.metrics.accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
